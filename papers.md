# Paper #
## Papers to read ##
- Book ["Social media mining"](http://dmml.asu.edu/smm/SMM.pdf) Zafarani, R. Abbasi M. A. Liu H. Cambridge University Press April 2014 Maybe Chapter III Applications, 9 Recommandation in Social Media?
- ["Designing interfaces for presentation of opinion diversity"](https://www.researchgate.net/publication/221515349_Designing_interfaces_for_presentation_of_opinion_diversity) Munson, S. A. Conference Preceedings for CHI 2009
- Filter bubbles:
    - [Curation Algorithms and Filter Bubbles in Social Networks](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2848526) Berman, R. Katona, Z. June 2018 NET Institute Working Paper No. 16-08
    - ["Filter Bubbles, echo chambers, and online news consumption"](https://5harad.com/papers/bubbles.pdf) Flaxman, S. Goel, S. Rao, J. M. Public Opinion Quarterly, Vol 80, Special Issue, 2016, 298-320
    - ["Fake news and ideological polarization: Filter bubbles and selective exposure on social media"](http://journals.sagepub.com/doi/pdf/10.1177/0266382117722446) Spohr, D. Business Information Review, 2017, Vol 34, 150-160
    - ["Beyond the filter bubble: concepts, myths, evidence and issues for future debates"](https://www.ivir.nl/publicaties/download/Beyond_the_filter_bubble__concepts_myths_evidence_and_issues_for_future_debates.pdf) Moeller, J. Helberger N. University of Amsterdam
- Sentiment analysis:
    - ["Twitter Sentiment Classification using Distant Supervision"](https://cs.stanford.edu/people/alecmgo/papers/TwitterDistantSupervision09.pdf) Go, A. Bhayani R. Huang, L. Stanford University
    - ["Twitter Sentiment Analysis: a review"](https://www.ijser.org/paper/Twitter-Sentiment-Analysis-A-Review.html)
    - ["Multiple Instance LEarning Networks for Fine-Grained Sentiment Analysis"](https://arxiv.org/pdf/1711.09645.pdf) Angelidis, S. Lapata, M. Transactions of the Association for Computational Linguistics, 2018, vol 6, 17-31
    - ["Sentiment Analysis on Twitter Data"](http://www.cs.columbia.edu/~julia/papers/Agarwaletal11.pdf) Agarwal, A. Xie, B. Columbia University
    - ["Sentiment Analysis on Twitter"](https://www.ijcsi.org/papers/IJCSI-9-4-3-372-378.pdf) Kumar, A. Sebastian, T. M. Delhi Technological University, IJCSI, 2012, Vol. 9
    - ["Thumbs up? Sentiment Classification using Machine Learning Techniques"](https://www.cs.cornell.edu/home/llee/papers/sentiment.pdf) Pang, B. Lee, L. Vaithyanathan, S. Proceedings of EMNLP 2002 79-86

## Papers read ##
## Social Media and Fake News in the 2016 Election ##
["Social Media and Fake News in the 2016 Election"](https://web.stanford.edu/~gentzkow/research/fakenews.pdf) Allcott, H. Gentzkow, M. Journal of Economic Perspectives - Vol. 31, No 2, Spring 2017, 211-236
This paper studied the creation and spread of fake news in the year leading up to 2016 US election. Social media has played a major role in the popularization of fake news. In early 2000s the move of news online created concerns including "excess diversity of viewpoints would make it easier for like-minded citizens to form "echo chambers" or "filter bubbles" where they would be insulated from contrary perspectives". Content online is relayed with no significant third party filtering, fact checking or editorial judgement and this is especially true on social media where people give credibility to stories because they were shared by someone they follow. An individual with no track record can reach as many readers as Fox News, CNN or the NYT.

From previous studies it was found that 62% of US adults get news on social media and for 14% of US adults social media was the most important source of election news. Most popular fake news stories were more widely shared on Facebook than the most popular mainstream news stories. The consequence of this is, as the paper suggests and proves, that Donald Trump would not have been elected president were it not for the influence of fake news.

To study fake news the authors sketch a model of supply and demand for news based on a previously formally defined model where "Consumers may derive psychological utility from seeing reports that are consistent with their priors. Consumers choose the firms from which they will consume news in order to maximise their own expected utility. They then use the content of the news reports they have consumed to form a posterior about the state of the world. Consumers receive psychological utility from confirmatory news. When feedback about the true state is limited, rational consumers will judge a firm to be higher quality when its reports are closer to the consumers' priors. Consumers may prefer reports that confirm their priors due to psychological utility."

The paper proves that social media platforms are especially conductive to fake news. Facebook friend networks are ideologically separated. People are more likely to read and share news articles that are aligned with their ideological positions. This suggests that people who get their news from social media are less likely to receive evidence about the true state of the world that would counter an ideologically alligned but false story.

People who report that social media were their most important sources of election news were more likely both to correctly believe true headline and to incorrectly believe false headlines. 

## WTF: The Who to Follow Service at Twitter ##
["WTF: The Who to Follow Service at Twitter"](http://stanford.edu/~rezab/papers/wtf_overview.pdf) Gupta, P. Goel, A. Lin, J. Sharma, A. Wang, D. Zadeh, R. Twitter, Inc. May 2013
WTF is the user recommendation service at Twitter. It suggests accounts the user might be interested in following based on shared interests, common connections and "a number of other factors". The two categories suggested profiles fall under are "similar to" and "interested in". The "similar to" category is used based on the homophily principle which is the tendency for individuals to bond with similar others. Converting new users into active users is a priority for social media services since user retention is strongly connected with the ability of the user to find communities to engage with. That's why the suggestion methods are prioritiezed towards new users. Making high-quality recommendations for new users is extremely challenging as they present a "cold start" problem - the network doesn't have much information about their interests they could dig into. If users are unable to find value in a service they are unlikely to return and that value is created by showing them content they'd most likely engage with. The algorithms for recommendations mentioned are Circle of Trust, SALSA and Real Graph.

- The circle of trust is a "primitive" in user recommendation and is just a personalized PageRank. This provides a basis for SALSA.
- SALSA uses a bipartite graph where on one side it puts ca 500 top-ranked nodes from a user's circle of trust and on the other it puts authorities which are profiles these 500 nodes follow creating a relationship between the two sides. The SALSA algorithm then assigns scores to both sides by a random walk and both sides are ranked by this score. Right hand side is then the standard "interested in" category whereas the left hand side ranking creates a group of "similar to you" profiles which are also suggested to the user.  
I.e. the profiles a user is shown are either profiles followed by many of user's current friends or profiles that are similar to the user. "A user u is likely to follow those who are followed by users that are similar to u."
- The Real Graph is a new approach possible because of distributing the graph with Hadoop. The Real Graph integrates user and behaviour features. Vertices represent users with metadata (#tweetss, #followers, #followings etc.) Edges represent relationships (follows, retweets, favourites, mentions etc or can add arbitrary weights). From this recommendations are computed in two phases:
    1. Candidate generation: produce a list of recommendations with many different algorithms, simple and complex (2-hop neighborhoods, personalized PageRanak, SALSA etc)
    2. Rescoring: apply an ML model to the candidate list. It's just a binary classification problem. The models are learned using the Pig-based framework. Logistic regression classifiers are trained using stochastic gradient descent in a single pass.

Recommendation information is used in search, content discovery, static priors in ranking etc.
